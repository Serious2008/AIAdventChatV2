//
//  SpeechRecognitionService.swift
//  AIAdventChatV2
//
//  Service for speech-to-text recognition using Apple Speech Framework
//

import Foundation
import Speech
import AVFoundation

// MARK: - Errors

enum SpeechRecognitionError: Error, LocalizedError {
    case notAuthorized
    case recognizerUnavailable
    case audioEngineError
    case recognitionFailed(String)

    var errorDescription: String? {
        switch self {
        case .notAuthorized:
            return "ÐÐµÑ‚ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð½Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð° Ð¸Ð»Ð¸ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÑ‡Ð¸"
        case .recognizerUnavailable:
            return "Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ Ð´Ð»Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ°"
        case .audioEngineError:
            return "ÐžÑˆÐ¸Ð±ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð²Ð¸Ð¶ÐºÐ°"
        case .recognitionFailed(let message):
            return "ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ: \(message)"
        }
    }
}

// MARK: - Speech Recognition Service

class SpeechRecognitionService: ObservableObject {

    // MARK: - Published Properties

    @Published var isRecording: Bool = false
    @Published var recognizedText: String = ""
    @Published var error: String?
    @Published var isAuthorized: Bool = false

    // MARK: - Private Properties

    private let speechRecognizer: SFSpeechRecognizer?
    private let audioEngine = AVAudioEngine()
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?

    // MARK: - Init

    init(locale: Locale = Locale(identifier: "ru-RU")) {
        speechRecognizer = SFSpeechRecognizer(locale: locale)

        // Check initial authorization
        Task {
            await checkAuthorization()
        }
    }

    // MARK: - Authorization

    /// Check current authorization status
    private func checkAuthorization() async {
        let speechStatus = SFSpeechRecognizer.authorizationStatus()

        await MainActor.run {
            self.isAuthorized = (speechStatus == .authorized)
        }
    }

    /// Request authorization for speech recognition and microphone
    func requestAuthorization() async -> Bool {
        print("ðŸŽ¤ Requesting speech recognition authorization...")

        // Request Speech Recognition authorization
        let speechAuth = await withCheckedContinuation { continuation in
            SFSpeechRecognizer.requestAuthorization { status in
                continuation.resume(returning: status == .authorized)
            }
        }

        guard speechAuth else {
            print("âŒ Speech recognition not authorized")
            await MainActor.run {
                self.error = "ÐÐµÑ‚ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð½Ð° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸"
                self.isAuthorized = false
            }
            return false
        }

        // Request Microphone authorization (macOS doesn't require explicit permission)
        #if os(iOS)
        let micAuth = await AVAudioSession.sharedInstance().requestRecordPermission()
        guard micAuth else {
            print("âŒ Microphone not authorized")
            await MainActor.run {
                self.error = "ÐÐµÑ‚ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð½Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°"
                self.isAuthorized = false
            }
            return false
        }
        #else
        // On macOS, microphone permission is handled by the system automatically
        let micAuth = true
        #endif

        guard micAuth else {
            print("âŒ Microphone not authorized")
            await MainActor.run {
                self.error = "ÐÐµÑ‚ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð½Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°"
                self.isAuthorized = false
            }
            return false
        }

        print("âœ… Authorization granted")
        await MainActor.run {
            self.isAuthorized = true
            self.error = nil
        }

        return true
    }

    // MARK: - Recording Control

    /// Start recording and speech recognition
    func startRecording() throws {
        print("ðŸŽ¤ Starting recording...")

        // Check if recognizer is available
        guard let speechRecognizer = speechRecognizer, speechRecognizer.isAvailable else {
            print("âŒ Speech recognizer unavailable")
            throw SpeechRecognitionError.recognizerUnavailable
        }

        // Cancel any ongoing task
        if recognitionTask != nil {
            recognitionTask?.cancel()
            recognitionTask = nil
        }

        // Configure audio session (iOS only)
        #if os(iOS)
        let audioSession = AVAudioSession.sharedInstance()
        try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        #endif
        // Note: On macOS, audio engine handles permissions automatically

        // Create recognition request
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()

        guard let recognitionRequest = recognitionRequest else {
            print("âŒ Unable to create recognition request")
            throw SpeechRecognitionError.audioEngineError
        }

        recognitionRequest.shouldReportPartialResults = true

        // If using on-device recognition (iOS 13+, macOS 10.15+)
        if #available(macOS 10.15, *) {
            recognitionRequest.requiresOnDeviceRecognition = false // Allow server-based for better accuracy
        }

        // Get input node
        let inputNode = audioEngine.inputNode

        // Start recognition task
        recognitionTask = speechRecognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            guard let self = self else { return }

            var isFinal = false

            if let result = result {
                // Update recognized text
                let transcription = result.bestTranscription.formattedString

                Task { @MainActor in
                    self.recognizedText = transcription
                    print("ðŸ“ Recognized: \(transcription)")
                }

                isFinal = result.isFinal
            }

            if error != nil || isFinal {
                // Stop audio engine
                self.audioEngine.stop()
                inputNode.removeTap(onBus: 0)

                self.recognitionRequest = nil
                self.recognitionTask = nil

                Task { @MainActor in
                    self.isRecording = false

                    if let error = error {
                        print("âŒ Recognition error: \(error.localizedDescription)")
                        self.error = error.localizedDescription
                    } else {
                        print("âœ… Recognition completed")
                    }
                }
            }
        }

        // Configure audio format
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            self.recognitionRequest?.append(buffer)
        }

        // Start audio engine
        audioEngine.prepare()
        try audioEngine.start()

        // Update state
        Task { @MainActor in
            self.isRecording = true
            self.recognizedText = ""
            self.error = nil
        }

        print("âœ… Recording started")
    }

    /// Stop recording and finalize recognition
    func stopRecording() {
        print("â¹ Stopping recording...")

        // Stop audio engine
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }

        // End recognition request
        recognitionRequest?.endAudio()

        // Deactivate audio session (iOS only)
        #if os(iOS)
        try? AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
        #endif

        // Update state
        Task { @MainActor in
            self.isRecording = false
        }

        print("âœ… Recording stopped")
    }

    /// Cancel recording without sending
    func cancelRecording() {
        print("âŒ Cancelling recording...")

        // Cancel recognition task
        recognitionTask?.cancel()
        recognitionTask = nil

        // Stop recording
        stopRecording()

        // Clear recognized text
        Task { @MainActor in
            self.recognizedText = ""
        }
    }

    // MARK: - Language Support

    /// Get available languages for speech recognition
    static func availableLanguages() -> [Locale] {
        return SFSpeechRecognizer.supportedLocales().sorted { locale1, locale2 in
            let name1 = locale1.localizedString(forIdentifier: locale1.identifier) ?? locale1.identifier
            let name2 = locale2.localizedString(forIdentifier: locale2.identifier) ?? locale2.identifier
            return name1 < name2
        }
    }

    /// Change recognition language
    func changeLanguage(to locale: Locale) {
        // This requires reinitializing the service
        // For now, just log
        print("ðŸŒ Language change requested to: \(locale.identifier)")
        print("âš ï¸ Language change requires app restart")
    }
}
